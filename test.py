import os
import argparse
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Subset
from torchvision import transforms
from tqdm import tqdm
from torch.cuda.amp import autocast
import numpy as np

# å¼•å…¥ä½ çš„é¡¹ç›®æ¨¡å—
from models.unet import UNet
from utils.dataset import TearMeniscusDataset
from utils.losses import DiceBCELoss
from utils.transforms import JointCompose, JointResize
from utils.metrics import (
    dice_coefficient, iou_score, accuracy_score,
    precision_score, recall_score, specificity_score,
    compute_hd95
)

def evaluate(model, dataloader, device):
    model.eval()
    
    metrics = {
        'dice': [], 'iou': [], 'acc': [], 
        'prec': [], 'recall': [], 'spec': [], 'hd95': []
    }
    
    print("æ­£åœ¨è®¡ç®—å„é¡¹æŒ‡æ ‡ (HD95 è®¡ç®—è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…)...")
    with torch.no_grad():
        for images, masks in tqdm(dataloader, desc='Testing'):
            images = images.to(device)
            masks = masks.to(device)

            with autocast():
                outputs = model(images)

            preds = (torch.sigmoid(outputs) > 0.5).float()
            
            # è½¬ä¸º numpy ç”¨äºè®¡ç®— HD95
            pred_np = preds.cpu().numpy().squeeze(1)
            mask_np = masks.cpu().numpy().squeeze(1)

            # é€å¼ è®¡ç®—æŒ‡æ ‡
            for i in range(images.size(0)):
                # åŸºç¡€æŒ‡æ ‡ (Tensorè®¡ç®—å¿«)
                p = preds[i]
                m = masks[i]
                metrics['dice'].append(dice_coefficient(p, m).item())
                metrics['iou'].append(iou_score(p, m).item())
                metrics['acc'].append(accuracy_score(p, m).item())
                metrics['prec'].append(precision_score(p, m).item())
                metrics['recall'].append(recall_score(p, m).item())
                metrics['spec'].append(specificity_score(p, m).item())
                
                # HD95 (Numpyè®¡ç®—æ…¢)
                # åªæœ‰å½“GTå’Œé¢„æµ‹éƒ½æœ‰å‰æ™¯æ—¶æ‰è®¡ç®—ï¼Œå¦åˆ™è·³è¿‡æˆ–ç»™æƒ©ç½š
                if np.sum(pred_np[i]) > 0 and np.sum(mask_np[i]) > 0:
                    metrics['hd95'].append(compute_hd95(pred_np[i], mask_np[i]))

    # è®¡ç®—å¹³å‡å€¼
    final_metrics = {k: np.mean(v) if len(v) > 0 else 0.0 for k, v in metrics.items()}
    return final_metrics

def main(args):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f'ğŸš€ Testing on device: {device}')

    # 1. å‡†å¤‡æµ‹è¯•é›†æ•°æ®
    print('ğŸ“¦ Loading Test Dataset...')
    test_joint = JointCompose([JointResize((args.img_size, args.img_size))])
    img_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    mask_transform = transforms.Compose([transforms.ToTensor()])

    # å®ä¾‹åŒ–æ•°æ®é›†
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬é‡æ–°åŠ è½½ä¸€éæ•°æ®æ¥åˆ’åˆ†ï¼Œç¡®ä¿å’Œè®­ç»ƒæ—¶ä¸€è‡´ï¼ˆä¾èµ–éšæœºç§å­ï¼‰
    # å¦‚æœä½ æƒ³å¿«ä¸€ç‚¹ï¼Œå¯ä»¥ç›´æ¥åªåŠ è½½ä¸€éƒ¨åˆ†ï¼Œä½†ä¸ºäº†ä¸¥è°¨ï¼Œæˆ‘ä»¬å¤ç°è®­ç»ƒæ—¶çš„åˆ’åˆ†é€»è¾‘
    ds_obj = TearMeniscusDataset(args.data_root, joint_transform=test_joint, transform=img_transform, target_transform=mask_transform)
    
    total_len = len(ds_obj)
    indices = torch.randperm(total_len, generator=torch.Generator().manual_seed(42)).tolist()
    
    train_len = int(0.7 * total_len)
    val_len = int(0.1 * total_len)
    test_indices = indices[train_len + val_len :]
    
    test_set = Subset(ds_obj, test_indices)
    print(f'   Test Set Size: {len(test_set)}')

    test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, num_workers=8, pin_memory=True)

    # 2. åˆå§‹åŒ–æ¨¡å‹
    model = UNet(n_channels=3, n_classes=1).to(device)

    # 3. ä¸‡èƒ½åŠ è½½é€»è¾‘ (æ ¸å¿ƒä¿®å¤)
    ckpt_path = os.path.join(args.checkpoint_dir, 'best_model.pth')
    print(f'ğŸ”“ Loading model from {ckpt_path}...')
    
    try:
        checkpoint = torch.load(ckpt_path, map_location=device)
        
        # æƒ…å†µA: è¿™æ˜¯ä¸€ä¸ªåŒ…å« 'epoch', 'model_state_dict' çš„å®Œæ•´å­—å…¸
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
            print("   -> Detected full checkpoint dict.")
        
        # æƒ…å†µB: è¿™ç›´æ¥å°±æ˜¯æƒé‡å­—å…¸ (KeyErrorçš„åŸå› é€šå¸¸æ˜¯è¿™ä¸ª)
        elif isinstance(checkpoint, dict):
            state_dict = checkpoint
            print("   -> Detected raw state_dict.")
        else:
            raise ValueError("Unknown checkpoint format")

        # å¤„ç† 'module.' å‰ç¼€ (é˜²æ­¢ DataParallel å¸¦æ¥çš„ key ä¸åŒ¹é…)
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith('module.'):
                new_state_dict[k[7:]] = v # å»æ‰ 'module.'
            else:
                new_state_dict[k] = v
        
        model.load_state_dict(new_state_dict)
        print("âœ… Model loaded successfully!")

    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        return

    # å¼€å¯å¤šå¡åŠ é€Ÿæµ‹è¯• (å¯é€‰)
    if torch.cuda.device_count() > 1:
        model = nn.DataParallel(model)

    # 4. å¼€å§‹æµ‹è¯•
    metrics = evaluate(model, test_loader, device)

    # 5. è¾“å‡ºæœ€ç»ˆæŠ¥è¡¨
    print('\n' + '='*40)
    print('ğŸ“„ FINAL SCI REPORT (Test Set Results)')
    print('='*40)
    print(f"Dice (DSC):    {metrics['dice']:.4f}")
    print(f"IoU (Jaccard): {metrics['iou']:.4f}")
    print(f"Accuracy:      {metrics['acc']:.4f}")
    print(f"Precision:     {metrics['prec']:.4f}")
    print(f"Recall:        {metrics['recall']:.4f}")
    print(f"Specificity:   {metrics['spec']:.4f}")
    print(f"HD95 (px):     {metrics['hd95']:.4f}")
    print('='*40)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_root', type=str, default='./dataset', help='path to dataset')
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--img_size', type=int, default=768) # ä¿æŒå’Œä½ è®­ç»ƒæ—¶ä¸€è‡´
    parser.add_argument('--checkpoint_dir', type=str, default='checkpoints')
    
    args = parser.parse_args()
    main(args)